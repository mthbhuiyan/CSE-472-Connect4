{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Connect4_C51.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WhXdJ4iJgBCF"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"OZR8eN1afNBp"},"source":["!pip install -q tf-agents"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPSiSv_DgHSb"},"source":["import numpy as np\r\n","import os\r\n","\r\n","from numba import jitclass, njit, int32, int64, float32\r\n","from tqdm import tqdm\r\n","from IPython.display import clear_output\r\n","\r\n","import tensorflow as tf\r\n","\r\n","from tf_agents.agents.categorical_dqn import categorical_dqn_agent\r\n","from tf_agents.drivers import dynamic_episode_driver\r\n","from tf_agents.environments import py_environment\r\n","from tf_agents.environments import tf_py_environment\r\n","from tf_agents.environments import utils\r\n","from tf_agents.metrics import tf_metrics\r\n","from tf_agents.networks import categorical_q_network\r\n","from tf_agents.policies import random_tf_policy\r\n","from tf_agents.replay_buffers import tf_uniform_replay_buffer\r\n","from tf_agents.specs import array_spec\r\n","from tf_agents.trajectories import policy_step\r\n","from tf_agents.trajectories import time_step as ts\r\n","from tf_agents.trajectories import trajectory\r\n","from tf_agents.utils import common\r\n","\r\n","tf.compat.v1.enable_v2_behavior()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L0sbaethhT_Z"},"source":["# Environment"]},{"cell_type":"markdown","metadata":{"id":"osU4dfkYhwnj"},"source":["## Board"]},{"cell_type":"code","metadata":{"id":"GXgqGvut5zwt"},"source":["@jitclass([('position', int64),\r\n","           ('mask', int64),\r\n","           ('n_move', int32),\r\n","           ('top', int64)])\r\n","class Connect4Board(object):\r\n","  def __init__(self, position=0, mask=0, n_move=0, top=None):\r\n","    self.position = position\r\n","    self.mask = mask\r\n","    self.n_move = n_move\r\n","\r\n","    if top is None:\r\n","      self.top = np.sum(1 << 6+7*np.arange(7))\r\n","    else:\r\n","      self.top = top\r\n","  \r\n","  def copy(self):\r\n","    return Connect4Board(self.position, self.mask, self.n_move, self.top)\r\n","  \r\n","  def reset(self):\r\n","    return Connect4Board(0, 0, 0, self.top)\r\n","\r\n","  def _reset(self):\r\n","    self.position = 0\r\n","    self.mask = 0\r\n","    self.n_move = 0\r\n","\r\n","    return self\r\n","\r\n","  def is_valid_move(self, col):\r\n","    return (self.top & (self.mask + (1 << (col*7))) == 0)\r\n","  \r\n","  def available_moves(self):\r\n","    return [col for col in range(7) if self.is_valid_move(col)]\r\n","  \r\n","  def generate_moves(self):\r\n","    return [col for col in np.random.choice(7, size=7, replace=False) if self.is_valid_move(col)]\r\n","\r\n","  def make_move(self, col):\r\n","    return Connect4Board(self.position ^ self.mask,\r\n","                         self.mask | (self.mask + (1 << (col*7))),\r\n","                         self.n_move + 1,\r\n","                         self.top)\r\n","\r\n","  def _make_move(self, col):\r\n","    self.position = self.position ^ self.mask\r\n","    self.mask = self.mask | (self.mask + (1 << (col*7)))\r\n","    self.n_move += 1\r\n","    return self\r\n","  \r\n","  def is_win(self):\r\n","    opposition = self.position ^ self.mask\r\n","    # Horizontal check\r\n","    m = opposition & (opposition >> 7)\r\n","    if m & (m >> 14):\r\n","        return True\r\n","    # Diagonal \\\r\n","    m = opposition & (opposition >> 6)\r\n","    if m & (m >> 12):\r\n","        return True\r\n","    # Diagonal /\r\n","    m = opposition & (opposition >> 8)\r\n","    if m & (m >> 16):\r\n","        return True\r\n","    # Vertical\r\n","    m = opposition & (opposition >> 1)\r\n","    if m & (m >> 2):\r\n","        return True\r\n","    # Nothing found\r\n","    return False\r\n","  \r\n","  def is_draw(self):\r\n","    return self.n_move == 42\r\n","  \r\n","  def is_terminal(self):\r\n","    return self.is_win() or self.is_draw()\r\n","  \r\n","  def to_array(self):\r\n","    board = np.zeros((6,7), dtype=np.int32)\r\n","\r\n","    opponent = self.position ^ self.mask\r\n","    p0, p1 = ((opponent, self.position) if self.n_move % 2 else \r\n","              (self.position, opponent))\r\n","    \r\n","    for j in range(7):\r\n","      m = np.int64(1) << j*7\r\n","      for i in range(6):\r\n","        if p0 & m:\r\n","          board[i,j] = 1\r\n","        elif p1 & m:\r\n","          board[i,j] = -1\r\n","        else:\r\n","          break\r\n","        m <<= 1\r\n","    \r\n","    return board\r\n","  \r\n","  def hash(self):\r\n","    return hash((self.position, self.mask))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4TZgiNLjh26t"},"source":["## Python Environment"]},{"cell_type":"code","metadata":{"id":"mwnAwk85fTi0"},"source":["class Connect4Env(py_environment.PyEnvironment):\r\n","\r\n","  def __init__(self):\r\n","    self._action_spec = array_spec.BoundedArraySpec(\r\n","        shape=(), dtype=np.int32, minimum=0, maximum=6, name='action')\r\n","    self._observation_spec = array_spec.BoundedArraySpec(\r\n","        shape=(6,7,1), dtype=np.float32, minimum=-1, maximum=1, name='observation')\r\n","    self._board = Connect4Board()\r\n","    self._episode_ended = False\r\n","\r\n","  def action_spec(self):\r\n","    return self._action_spec\r\n","\r\n","  def observation_spec(self):\r\n","    return self._observation_spec\r\n","\r\n","  def _reset(self):\r\n","    self._board._reset()\r\n","    self._episode_ended = False\r\n","    return ts.restart(self._board.to_array()[:,:,np.newaxis].astype(np.float32))\r\n","\r\n","  def _step(self, action):\r\n","\r\n","    if self._episode_ended:\r\n","      # The last action ended the episode. Ignore the current action and start\r\n","      # a new episode.\r\n","      return self.reset()\r\n","\r\n","    # Make sure episodes don't go on forever.\r\n","    if action < 0 or action > 6:\r\n","      raise ValueError('`action` should be between 0 to 6.')\r\n","    elif not self._board.is_valid_move(action):\r\n","      self._episode_ended = True\r\n","      return ts.termination(self._board.to_array()[:,:,np.newaxis].astype(np.float32), reward=-25.0)\r\n","    \r\n","    self._board._make_move(action)\r\n","\r\n","    if self._board.is_win():\r\n","      self._episode_ended = True\r\n","      return ts.termination(self._board.to_array()[:,:,np.newaxis].astype(np.float32), reward=1.0)\r\n","    elif self._board.is_draw():\r\n","      self._episode_ended = True\r\n","      return ts.termination(self._board.to_array()[:,:,np.newaxis].astype(np.float32), reward=0.0)\r\n","    else:\r\n","      return ts.transition(self._board.to_array()[:,:,np.newaxis].astype(np.float32), reward=0.0, discount=1.0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VrzM_NPDk6YC"},"source":["# Negamax"]},{"cell_type":"markdown","metadata":{"id":"TrGCLK2vlMzs"},"source":["## Evaluator"]},{"cell_type":"code","metadata":{"id":"RPg_ocOMPhDf"},"source":["@njit\r\n","def bitwise_or_reduce(xs):\r\n","  s = 0\r\n","  for x in xs:\r\n","    s |= x\r\n","\r\n","  return s\r\n","\r\n","@jitclass([('i_bottom', int32[:]),\r\n","           ('bottom', int64),\r\n","           ('cols', int64[:]),\r\n","           ('d', int32[:]),\r\n","           ('weights', float32[:,::1])])\r\n","class Connect4Evaluator(object):\r\n","  def __init__(self):\r\n","    self.i_bottom = np.int32(7) * np.arange(7, dtype=np.int32)\r\n","    self.bottom = np.sum(1 << self.i_bottom)\r\n","    self.cols = ((np.int64(1) << 7) - 1) << self.i_bottom\r\n","    self.d = np.array([7,6,8,1], dtype=np.int32)\r\n","    self.weights = np.array([[0.001,0.009,0.09,0.9],\r\n","                             [0.001,0.009,0.09,0.4]], dtype=np.float32)\r\n","\r\n","  def evaluate(self, board: Connect4Board, color=1):\r\n","    # if last player won then current player lost\r\n","    if board.is_win():\r\n","      return (board.n_move + 1) // 2 - 22.0\r\n","    # game drawn\r\n","    elif board.is_draw():\r\n","      return 0.0\r\n","    # intermediate state\r\n","    else:\r\n","      mask = board.mask | board.top\r\n","      cur_n = self._evaluate(board.position, mask)\r\n","      opp_n = self._evaluate(board.position ^ board.mask, mask)\r\n","      max_score = 21.0 - board.n_move // 2\r\n","      cur_value = np.dot(cur_n, self.weights[0])\r\n","      if cur_value >= 1.0:\r\n","        return 21.0 - board.n_move // 2\r\n","      opp_value = np.dot(opp_n, self.weights[1])\r\n","      if opp_value >= 1.0:\r\n","        return (board.n_move+1) // 2 - 21.0\r\n","      return (21.0 - (board.n_move+2) // 2) * (cur_value - opp_value)\r\n","  \r\n","  def _evaluate(self, pos, mask):\r\n","    n_mask = ~mask\r\n","    nxt = mask + self.bottom\r\n","\r\n","    # lij : at least i consecutive elements starting withing j places on left\r\n","    l11 = pos >> self.d\r\n","    l12 = l11 | (l11 & n_mask) >> self.d\r\n","    l13 = l12 | (l12 & n_mask) >> self.d\r\n","\r\n","    l21 = l11 & (l11 >> self.d)\r\n","    l22 = l21 | (l21 & n_mask) >> self.d\r\n","\r\n","    l31 = l21 & (l21 >> self.d)\r\n","\r\n","    # rij : at least i consecutive elements starting withing j places on right\r\n","    r11 = pos << self.d\r\n","    r12 = r11 | (r11 & n_mask) << self.d\r\n","    r13 = r12 | (r12 & n_mask) << self.d\r\n","\r\n","    r21 = r11 & (r11 << self.d)\r\n","    r22 = r21 | (r21 & n_mask) << self.d\r\n","\r\n","    r31 = r21 & (r21 << self.d)\r\n","\r\n","    # ci : at least i elements within a 4 element frame that contains it\r\n","    c1 = bitwise_or_reduce((l13 | r13) & n_mask)\r\n","    c2 = bitwise_or_reduce((l22 | r22 | (l11 & r12) | (l12 & r11)) & n_mask)\r\n","    c3 = bitwise_or_reduce((l31 | r31 | (l21 & r11) | (l11 & r21)) & n_mask)\r\n","    # c3t : adding one more here will make it win\r\n","    c3t = c3 & nxt\r\n","\r\n","    c = np.array([[c1],[c2],[c3],[c3t]])\r\n","\r\n","    n = np.sum((c & self.cols) != 0, axis=1, dtype=np.float32)\r\n","\r\n","    return n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ovzoOMPjlYd1"},"source":["## Searcher"]},{"cell_type":"code","metadata":{"id":"Uk462q8pFNhu"},"source":["class TranspositionTableEntry(object):\r\n","  def __init__(self, value, flag, depth):\r\n","    self.value = value\r\n","    self.flag = flag\r\n","    self.depth = depth\r\n","\r\n","class NegamaxSearcher(object):\r\n","  EXACT = 0\r\n","  LOWERBOUND = -1\r\n","  UPPERBOUND = 1\r\n","  def __init__(self, evaluator):\r\n","    self.evaluate = np.vectorize(evaluator.evaluate)\r\n","  \r\n","  def __call__(self, node, depth) -> int:\r\n","    # initialize tranposition table\r\n","    self.t_table = {}\r\n","\r\n","    moves = np.array(node.generate_moves())\r\n","    if depth<=0:\r\n","      return moves[0]\r\n","    children = np.array([node.make_move(move) for move in moves])\r\n","\r\n","    values = self.evaluate(children, -1)\r\n","    if depth == 1:\r\n","      index = np.argmax(-values)\r\n","      return moves[index]\r\n","\r\n","    order = values.argsort()\r\n","\r\n","    value = (-np.inf, None)\r\n","    a, b = -np.inf, np.inf\r\n","    for move,child in zip(moves[order],children[order]):\r\n","      value = max(value, (-self._negamax(child, depth-1, -b, -a, -1), move), key=lambda x: x[0])\r\n","      a = max(a, value[0])\r\n","      if a >= b:\r\n","        break\r\n","    \r\n","    return value[1]\r\n","\r\n","  def _negamax(self, node, depth, a, b, color) -> float:\r\n","    a_orig = a\r\n","    \r\n","    # Transposition Table Lookup; node is the lookup key for t_entry\r\n","    t_entry = self.t_table.get(node.hash())\r\n","    if t_entry is not None and t_entry.depth >= depth:\r\n","      if t_entry.flag == self.EXACT:\r\n","        return t_entry.value\r\n","      elif t_entry.flag == self.LOWERBOUND:\r\n","        a = max(a, t_entry.value)\r\n","      elif t_entry.flag == self.UPPERBOUND:\r\n","        b = min(b, t_entry.value)\r\n","      \r\n","      if a >= b:\r\n","        return t_entry.value\r\n","\r\n","    \r\n","    if depth < 1 or node.is_terminal():\r\n","      return self.evaluate(node, color)\r\n","    \r\n","    moves = node.generate_moves()\r\n","    children = np.array([node.make_move(move) for move in moves])\r\n","\r\n","    values = self.evaluate(children, -color)\r\n","    if depth == 1:\r\n","      return np.max(-values)\r\n","\r\n","    order = values.argsort()\r\n","\r\n","    value = -np.inf\r\n","    for child in children[order]:\r\n","      value = max(value, -self._negamax(child, depth-1, -b, -a, -color))\r\n","      a = max(a, value)\r\n","      if a >= b:\r\n","        break\r\n","    \r\n","    # Transposition Table Store; node is the lookup key for t_entry\r\n","    if value <= a_orig:\r\n","      flag = self.UPPERBOUND\r\n","    elif value >= b:\r\n","      flag = self.LOWERBOUND\r\n","    else:\r\n","      flag = self.EXACT\r\n","    \r\n","    t_entry = TranspositionTableEntry(value, flag, depth)\r\n","    self.t_table[node.hash()] = t_entry\r\n","    \r\n","    return value"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LsP0yyjV5Ab6"},"source":["# Custom Drivers"]},{"cell_type":"markdown","metadata":{"id":"XgAbHS8m5Njt"},"source":["Play Against Negamax"]},{"cell_type":"code","metadata":{"id":"OJdeTicdWlPo"},"source":["class NegamaxEpisodeDriver(object):\r\n","  def __init__(self, env, policy, observers=(), num_episodes=10, depth=2, mirroring=False):\r\n","    self.env = env\r\n","    self.policy = policy\r\n","    self.observers = observers\r\n","    self.num_episodes = num_episodes\r\n","    self.depth = depth\r\n","    self.mirror = mirroring\r\n","    self.board = Connect4Board()\r\n","    self.negamax = NegamaxSearcher(Connect4Evaluator())\r\n","  \r\n","  def run(self, first):\r\n","    for _ in range(self.num_episodes):\r\n","      turn = (first == 0)\r\n","      self.board._reset()\r\n","      time_step = self.env.reset()\r\n","      action_buffer = []\r\n","      while not time_step.is_last():\r\n","        if turn:\r\n","          action_step = self.policy.action(time_step)\r\n","          tf_action = action_step.action\r\n","          py_action = tf_action.numpy()[0]\r\n","        else:\r\n","          py_action = self.negamax(self.board, self.depth)\r\n","          tf_action = tf.constant([py_action])\r\n","          action_step = policy_step.PolicyStep(tf_action)\r\n","        self.board._make_move(py_action)\r\n","        next_time_step = self.env.step(tf_action)\r\n","        traj = trajectory.from_transition(time_step, action_step, next_time_step)\r\n","        action_buffer.append(tf_action)\r\n","\r\n","        # Add trajectory to the replay buffer\r\n","        for observer in self.observers:\r\n","          observer(traj)\r\n","        \r\n","        time_step = next_time_step\r\n","        turn = not turn\r\n","      \r\n","      if not self.mirror:\r\n","        continue\r\n","      \r\n","      time_step = self.env.reset()\r\n","      for tf_action in action_buffer:\r\n","        action = 6-tf_action\r\n","        action_step = policy_step.PolicyStep(action)\r\n","        next_time_step = self.env.step(action)\r\n","        traj = trajectory.from_transition(time_step, action_step, next_time_step)\r\n","\r\n","        # Add trajectory to the replay buffer\r\n","        for observer in self.observers:\r\n","          observer(traj)\r\n","        \r\n","        time_step = next_time_step"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RRWZcg5T5Z_O"},"source":["Play Against Each-other"]},{"cell_type":"code","metadata":{"id":"KK1SEfBTxvoN"},"source":["class NashEpisodeDriver(object):\r\n","  def __init__(self, env, policies, observers=(), num_episodes=10, mirroring=False):\r\n","    self.env = env\r\n","    self.policies = policies\r\n","    self.n_policies = len(policies)\r\n","    self.observers = observers\r\n","    self.num_episodes = num_episodes\r\n","    self.mirror = mirroring\r\n","  \r\n","  def run(self, first):\r\n","    for _ in range(self.num_episodes):\r\n","      turn = first % self.n_policies\r\n","      time_step = self.env.reset()\r\n","      action_buffer = []\r\n","      while not time_step.is_last():\r\n","        policy = self.policies[turn]\r\n","        action_step = policy.action(time_step)\r\n","        next_time_step = self.env.step(action_step.action)\r\n","        traj = trajectory.from_transition(time_step, action_step, next_time_step)\r\n","        action_buffer.append(action_step.action)\r\n","\r\n","        # Add trajectory to the replay buffer\r\n","        for observer in self.observers:\r\n","          observer(traj)\r\n","      \r\n","        time_step = next_time_step\r\n","        turn = (turn + 1) % self.n_policies\r\n","      \r\n","      if not self.mirror:\r\n","        continue\r\n","      \r\n","      time_step = self.env.reset()\r\n","      for action in action_buffer:\r\n","        action = 6-action\r\n","        action_step = policy_step.PolicyStep(action)\r\n","        next_time_step = self.env.step(action)\r\n","        traj = trajectory.from_transition(time_step, action_step, next_time_step)\r\n","\r\n","        # Add trajectory to the replay buffer\r\n","        for observer in self.observers:\r\n","          observer(traj)\r\n","        \r\n","        time_step = next_time_step"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0dK4Rs54U01"},"source":["# Custom Metric"]},{"cell_type":"code","metadata":{"id":"2zPqMGabk060"},"source":["class DiscountedReturnMetric(object):\r\n","  def __init__(self, buffer_size=10, gamma=1.0):\r\n","    self.buffer = np.zeros(buffer_size, dtype=np.float64)\r\n","    self.index = 0\r\n","    self.buffer_size = buffer_size\r\n","    self.gamma = gamma\r\n","  \r\n","  def init_variables(self):\r\n","    self.current_return = 0.0\r\n","    self.current_factor = 1.0\r\n","  \r\n","  def call(self, trajectory):\r\n","    if trajectory.is_first():\r\n","      self.init_variables()\r\n","    self.current_return += self.current_factor * trajectory.reward.numpy()\r\n","    self.current_factor *= self.gamma\r\n","    if trajectory.is_last():\r\n","      self.buffer[self.index] = self.current_return\r\n","      self.index = (self.index + 1) % self.buffer_size\r\n","  \r\n","  def result(self):\r\n","    # return np.mean(self.buffer)\r\n","    n_win = np.count_nonzero(self.buffer > 0)\r\n","    n_lose = np.count_nonzero(self.buffer < 0)\r\n","    n_draw = self.buffer_size - (n_win + n_lose)\r\n","    return (n_win, n_draw, n_lose)\r\n","  \r\n","  def __call__(self, trajectory):\r\n","    self.call(trajectory)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaUxQw8g3EK4"},"source":["# Categorical DQN (C51) Agent"]},{"cell_type":"markdown","metadata":{"id":"h8OTyXwn3TTr"},"source":["## Hyperparameters"]},{"cell_type":"code","metadata":{"id":"DNk_jXAL3aJ0"},"source":["num_iterations = 2000000\r\n","\r\n","num_collect_episodes = 2\r\n","collect_interval = 50\r\n","replay_buffer_capacity = 40000\r\n","\r\n","conv_layer_params = ((256,(4,4),1),)\r\n","fc_layer_params = (256,256,128,64,32,)\r\n","\r\n","gamma = -0.99\r\n","\r\n","batch_size = 64\r\n","learning_rate = 1e-3\r\n","log_interval = 100\r\n","\r\n","num_atoms = 51\r\n","min_q_value = -1.0\r\n","max_q_value = 1.0\r\n","n_step_update = 2\r\n","\r\n","num_eval_episodes = 5\r\n","eval_interval = 1000\r\n","\r\n","checkpoint_interval = 10000\r\n","switch_interval = 1000\r\n","clear_interval = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U9letwZ43bSG"},"source":["## Environment"]},{"cell_type":"code","metadata":{"id":"c-ruXi-n2Bae"},"source":["train_py_env = Connect4Env()\r\n","eval_py_env = Connect4Env()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqxGjaLS3hlM"},"source":["train_env = tf_py_environment.TFPyEnvironment(train_py_env)\r\n","eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vypdiu2L3ijK"},"source":["## Agent"]},{"cell_type":"code","metadata":{"id":"ET-NO7DU3nSy"},"source":["categorical_q_net = categorical_q_network.CategoricalQNetwork(\r\n","    train_env.observation_spec(),\r\n","    train_env.action_spec(),\r\n","    num_atoms=num_atoms,\r\n","    conv_layer_params=conv_layer_params,\r\n","    fc_layer_params=fc_layer_params)\r\n","\r\n","optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\r\n","\r\n","global_step = tf.compat.v1.train.get_or_create_global_step()\r\n","\r\n","agent = categorical_dqn_agent.CategoricalDqnAgent(\r\n","    train_env.time_step_spec(),\r\n","    train_env.action_spec(),\r\n","    categorical_q_network=categorical_q_net,\r\n","    optimizer=optimizer,\r\n","    min_q_value=min_q_value,\r\n","    max_q_value=max_q_value,\r\n","    n_step_update=n_step_update,\r\n","    td_errors_loss_fn=common.element_wise_squared_loss,\r\n","    gamma=gamma,\r\n","    train_step_counter=global_step)\r\n","agent.initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CnZT3oDJ3mtr"},"source":["## Data Collection"]},{"cell_type":"code","metadata":{"id":"MPzBYrJGxISd"},"source":["replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\r\n","    data_spec=agent.collect_data_spec,\r\n","    batch_size=train_env.batch_size,\r\n","    max_length=replay_buffer_capacity)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YumntnCQw4Aj"},"source":["negamax_collect_driver = NegamaxEpisodeDriver(\r\n","    train_env,\r\n","    agent.collect_policy,\r\n","    observers=[replay_buffer.add_batch],\r\n","    num_episodes=num_collect_episodes,\r\n","    depth=1,\r\n","    mirroring=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1ag-gWPw7EF"},"source":["random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\r\n","                                                train_env.action_spec())\r\n","\r\n","random_collect_driver = NegamaxEpisodeDriver(\r\n","    train_env,\r\n","    agent.collect_policy,\r\n","    observers=[replay_buffer.add_batch],\r\n","    num_episodes=num_collect_episodes,\r\n","    depth=0,\r\n","    mirroring=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1Jn6FSlD4mM"},"source":["selfplay_collect_driver = NashEpisodeDriver(\r\n","    train_env,\r\n","    [agent.policy, agent.collect_policy],\r\n","    observers=[replay_buffer.add_batch],\r\n","    num_episodes=num_collect_episodes,\r\n","    mirroring=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUY4FjltxC9q"},"source":["# Initial data collection\r\n","random_collect_driver.run(first=True)\r\n","random_collect_driver.run(first=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NzNkEBwrZfaR"},"source":["# Dataset generates trajectories with shape [BxTx...] where\r\n","# T = n_step_update + 1.\r\n","dataset = replay_buffer.as_dataset(\r\n","    num_parallel_calls=3, sample_batch_size=batch_size,\r\n","    num_steps=n_step_update + 1).prefetch(3)\r\n","\r\n","iterator = iter(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h0fzPOAO3vfm"},"source":["## Evaluation Metrics"]},{"cell_type":"code","metadata":{"id":"x4WdLkTL38Yy"},"source":["eval_metrics = [DiscountedReturnMetric(buffer_size=num_eval_episodes, gamma=gamma)]\r\n","negamax_eval_driver = NegamaxEpisodeDriver(\r\n","    eval_env,\r\n","    agent.policy,\r\n","    observers=eval_metrics,\r\n","    num_episodes=num_eval_episodes,\r\n","    depth=1)\r\n","\r\n","random_eval_driver = NashEpisodeDriver(\r\n","    eval_env,\r\n","    [agent.policy, random_policy],\r\n","    observers=eval_metrics,\r\n","    num_episodes=num_eval_episodes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ro2Ygk1c4BRb"},"source":["## Checkpoint"]},{"cell_type":"code","metadata":{"id":"cVZ4vQoi4Sgx"},"source":["checkpoint_dir = os.path.join('/content/drive/MyDrive/connect4_checkpoint_v3', 'connect4_c51_checkpoint')\r\n","train_checkpointer = common.Checkpointer(\r\n","    ckpt_dir=checkpoint_dir,\r\n","    max_to_keep=1,\r\n","    agent=agent,\r\n","    policy=agent.policy,\r\n","    replay_buffer=replay_buffer,\r\n","    global_step=global_step\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AG5TCdSBOfWr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZwKbV3nedYO","executionInfo":{"status":"ok","timestamp":1608540073230,"user_tz":-360,"elapsed":965,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"b866543f-96ea-4f10-873c-d2aaef68afb4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D6q8r75orh9Q"},"source":["train_checkpointer.initialize_or_restore()\r\n","global_step = tf.compat.v1.train.get_global_step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bB5ud8ciRAMd","executionInfo":{"status":"ok","timestamp":1608540121756,"user_tz":-360,"elapsed":940,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"b8777727-4d14-402c-addc-c1d7d3c15963"},"source":["print(global_step)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<tf.Variable 'global_step:0' shape=() dtype=int64, numpy=2000000>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CCad7fw939SF"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"6bpWlwFyymiv"},"source":["# (Optional) Optimize by wrapping some of the code in a graph using TF function.\r\n","agent.train = common.function(agent.train)\r\n","\r\n","collect_driver = dynamic_episode_driver.DynamicEpisodeDriver(\r\n","    train_env,\r\n","    agent.collect_policy,\r\n","    observers=[replay_buffer.add_batch],\r\n","    num_episodes=num_collect_episodes)\r\n","\r\n","def train_one_iteration():\r\n","\r\n","  # Sample a batch of data from the buffer and update the agent's network.\r\n","  experience, unused_info = next(iterator)\r\n","  train_loss = agent.train(experience).loss\r\n","  losses=[]\r\n","  random_returns = []\r\n","  negamax_returns = []\r\n","  step = agent.train_step_counter.numpy()\r\n","  \r\n","  if step % log_interval == 0:\r\n","    losses.append((step, train_loss))\r\n","\r\n","  if step % eval_interval == 0:\r\n","    random_eval_driver.run(first=0)\r\n","    avg_return0 = eval_metrics[0].result()\r\n","    random_eval_driver.run(first=1)\r\n","    avg_return1 = eval_metrics[0].result()\r\n","    random_returns.append((step, avg_return0, avg_return1))\r\n","    \r\n","    negamax_eval_driver.run(first=0)\r\n","    avg_return0 = eval_metrics[0].result()\r\n","    negamax_eval_driver.run(first=1)\r\n","    avg_return1 = eval_metrics[0].result()\r\n","    negamax_returns.append((step, avg_return0, avg_return1))\r\n","    \r\n","  if step % checkpoint_interval == 0:\r\n","    train_checkpointer.save(global_step)\r\n","\r\n","def train_v3():\r\n","  for _ in tqdm(range(2000)):\r\n","    for first in range(2):\r\n","      for _ in range(3):\r\n","        negamax_collect_driver.run(first)\r\n","        for _ in range(50):\r\n","          train_one_iteration()\r\n","      for _ in range(3):\r\n","        random_collect_driver.run(first)\r\n","        for _ in range(50):\r\n","          train_one_iteration()\r\n","      for _ in range(4):\r\n","        collect_driver.run()\r\n","        for _ in range(50):\r\n","          train_one_iteration()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lLGGU1jd3_cD"},"source":["# (Optional) Optimize by wrapping some of the code in a graph using TF function.\r\n","agent.train = common.function(agent.train)\r\n","\r\n","def train(collect_drivers):\r\n","\r\n","  turn = 0\r\n","  n_drivers = len(collect_drivers)\r\n","  losses=[]\r\n","  random_returns = []\r\n","  negamax_returns = []\r\n","  step = agent.train_step_counter.numpy()\r\n","  \r\n","  for _ in tqdm(range(num_iterations)):\r\n","    \r\n","    if step % switch_interval == 0:\r\n","      collect_driver = collect_drivers[turn]\r\n","      turn = (turn + 1) % n_drivers\r\n","\r\n","    # Collect a few steps using collect_policy and save to the replay buffer.\r\n","    if step % collect_interval == 0:\r\n","      collect_driver.run(first=0)\r\n","      collect_driver.run(first=1)\r\n","\r\n","    # Sample a batch of data from the buffer and update the agent's network.\r\n","    experience, unused_info = next(iterator)\r\n","    train_loss = agent.train(experience).loss\r\n","\r\n","    step += 1\r\n","    \r\n","    if step % log_interval == 0:\r\n","      losses.append((step, train_loss))\r\n","\r\n","    if step % eval_interval == 0:\r\n","      random_eval_driver.run(first=0)\r\n","      avg_return0 = eval_metrics[0].result()\r\n","      random_eval_driver.run(first=1)\r\n","      avg_return1 = eval_metrics[0].result()\r\n","      random_returns.append((step, avg_return0, avg_return1))\r\n","      \r\n","      negamax_eval_driver.run(first=0)\r\n","      avg_return0 = eval_metrics[0].result()\r\n","      negamax_eval_driver.run(first=1)\r\n","      avg_return1 = eval_metrics[0].result()\r\n","      negamax_returns.append((step, avg_return0, avg_return1))\r\n","    \r\n","    if step % checkpoint_interval == 0:\r\n","      train_checkpointer.save(global_step)\r\n","  \r\n","  return losses, (random_returns, negamax_returns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GN1OB6WAcAhm"},"source":["train_checkpointer.save(global_step)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtA2GvQAq-iv","executionInfo":{"status":"ok","timestamp":1608478250398,"user_tz":-360,"elapsed":3832510,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"6732d3b3-02e7-4664-a11d-9851f89e757a"},"source":["losses, returns = train([selfplay_collect_driver])\r\n","import pickle\r\n","with open('/content/drive/MyDrive/connect4_stats/losses_v8.pickle', 'wb') as f:\r\n","    pickle.dump(losses, f)\r\n","with open('/content/drive/MyDrive/connect4_stats/returns_v8.pickle', 'wb') as f:\r\n","    pickle.dump(returns, f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 200000/200000 [1:03:51<00:00, 52.20it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"id":"zAkvJGLl2KVC","executionInfo":{"status":"error","timestamp":1608518203577,"user_tz":-360,"elapsed":866512,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"4de069ed-d3ae-4eec-ec71-5dd5db4327a7"},"source":["losses, returns = train_v3()\r\n","# import pickle\r\n","# with open('/content/drive/MyDrive/connect4_stats/losses_v8.pickle', 'wb') as f:\r\n","#     pickle.dump(losses, f)\r\n","# with open('/content/drive/MyDrive/connect4_stats/returns_v8.pickle', 'wb') as f:\r\n","#     pickle.dump(returns, f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 2000/2000 [5:51:25<00:00, 10.54s/it]\n"],"name":"stderr"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-7b9dc1b5bdc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/connect4_stats/losses_v8.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/connect4_stats/returns_v8.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"IRYO6Hei2Dqf","executionInfo":{"status":"error","timestamp":1608529763802,"user_tz":-360,"elapsed":1719,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"1538f1ff-b24b-4d1f-90bc-00280154032a"},"source":[""],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-36a7304af396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreturns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'returns' is not defined"]}]},{"cell_type":"code","metadata":{"id":"rJJzvrKVQDEp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":229},"id":"C43vobh5TKru","executionInfo":{"status":"error","timestamp":1608530220529,"user_tz":-360,"elapsed":922,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"ed8ee2fb-20b6-4d79-cf7e-d6900a1a39f5"},"source":["import pickle\r\n","with open('/content/drive/MyDrive/connect4_stats/losses_v8.pickle', 'rb') as f:\r\n","     pick_loss = pickle.load(f)\r\n","with open('/content/drive/MyDrive/connect4_stats/returns_v8.pickle', 'rb') as f:\r\n","     pick_returns = pickle.load(f)\r\n","print(pick_loss)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-184f27478c2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/connect4_stats/losses_v8.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m      \u001b[0mpick_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/connect4_stats/returns_v8.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0mpick_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/connect4_stats/losses_v8.pickle'"]}]},{"cell_type":"code","metadata":{"id":"tpid9oi1qG8b"},"source":["losses=pick_loss\r\n","returns=pick_returns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":229},"id":"zlLbcJLQlCHD","executionInfo":{"status":"error","timestamp":1608537486385,"user_tz":-360,"elapsed":950,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"51a72208-96c8-408e-e8fc-434497d8d431"},"source":["%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","\r\n","random_returns, negamax_returns = returns\r\n","\r\n","x, y1, y2 = zip(*random_returns)\r\n","y1w, y1d, y1l = zip(*y1)\r\n","y2l, y2d, y2w = zip(*y2)\r\n","\r\n","fig, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True)\r\n","\r\n","ax1.plot(x, y1w, 'tab:green')\r\n","ax1.plot(x, y1d, 'tab:blue')\r\n","ax1.plot(x, y1l, 'tab:red')\r\n","\r\n","ax2.plot(x, y2w, 'tab:green')\r\n","ax2.plot(x, y2d, 'tab:blue')\r\n","ax2.plot(x, y2l, 'tab:red')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-5c4842e25cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrandom_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegamax_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'returns' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"mFk0XbUX4mTV"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"KzOOjsND3j3K"},"source":["def print_board(a):\r\n","  for i in range(6,-1,-1):\r\n","    m = np.int64(1) << i\r\n","    for _ in range(7):\r\n","      if a & m:\r\n","        print('1', end='')\r\n","      else:\r\n","        print('0', end='')\r\n","      m <<= 7\r\n","    print('')\r\n","\r\n","c4Ev = Connect4Evaluator()\r\n","board = Connect4Board()\r\n","# board._make_move(3)\r\n","# board._make_move(3)\r\n","# board._make_move(2)\r\n","# board._make_move(2)\r\n","# board._make_move(1)\r\n","# mask= board.mask\r\n","# pos = board.position ^ mask\r\n","\r\n","# print(np.flipud(board.to_array()))\r\n","# print()\r\n","# n = c4Ev.evaluate(board)\r\n","# boards = c4Ev.order_moves(board.generate_moves())\r\n","# for i, b in enumerate(boards):\r\n","#   print(i)\r\n","#   print(c4Ev.evaluate(b))\r\n","#   print(np.flipud(b.to_array()))\r\n","# print(n)\r\n","negamax = NegamaxSearcher(c4Ev)\r\n","# %time ngmx.negamax(board, 6)\r\n","def run(board):\r\n","  while not board.is_terminal():\r\n","    col = negamax(board, 6)\r\n","    board = board.make_move(col)\r\n","    yield col\r\n","\r\n","# %time cols = list(run(board))\r\n","# print(len(cols), cols)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZzLXqf8GTTA"},"source":["def print_trajectory(trajectory):\r\n","  print(np.flipud(trajectory.observation.numpy().reshape((6,7))))\r\n","  print(trajectory.action.numpy())\r\n","  print(trajectory.reward.numpy())\r\n","\r\n","negamax_test_driver = NegamaxEpisodeDriver(\r\n","    eval_env,\r\n","    agent.policy,\r\n","    observers=[print_trajectory],\r\n","    num_episodes=1,\r\n","    depth=1)\r\n","\r\n","random_test_driver = NashEpisodeDriver(\r\n","    eval_env,\r\n","    [agent.policy, random_policy],\r\n","    observers=[print_trajectory],\r\n","    num_episodes=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m0taFs1CxthJ","executionInfo":{"status":"ok","timestamp":1608539192195,"user_tz":-360,"elapsed":995,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"2b561de9-37ec-4a3d-cde6-ec5bafb984ed"},"source":["negamax_test_driver.run(first=0) # agent is 1st player\r\n","#random_test_driver.run(first=1)  # agent is 2nd player"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]]\n","[3]\n","[0.]\n","[[0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0.]]\n","[3]\n","[0.]\n","[[ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0. -1.  0.  0.  0.]\n"," [ 0.  0.  0.  1.  0.  0.  0.]]\n","[4]\n","[0.]\n","[[ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0. -1.  0.  0.  0.]\n"," [ 0.  0.  0.  1.  1.  0.  0.]]\n","[4]\n","[0.]\n","[[ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0. -1. -1.  0.  0.]\n"," [ 0.  0.  0.  1.  1.  0.  0.]]\n","[2]\n","[0.]\n","[[ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0. -1. -1.  0.  0.]\n"," [ 0.  0.  1.  1.  1.  0.  0.]]\n","[0]\n","[0.]\n","[[ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0. -1. -1.  0.  0.]\n"," [-1.  0.  1.  1.  1.  0.  0.]]\n","[5]\n","[1.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zvkgAiEnqUBH","executionInfo":{"status":"ok","timestamp":1608540159311,"user_tz":-360,"elapsed":7141,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"ae41b991-554c-429e-8818-c9572c2e6a7a"},"source":["negamax_eval_driver.run(first=0)\r\n","eval_metrics[0].result()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).agent._optimizer.beta1_power\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).agent._optimizer.beta1_power\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).agent._optimizer.beta2_power\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).agent._optimizer.beta2_power\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(5, 0, 0)"]},"metadata":{"tags":[]},"execution_count":150}]},{"cell_type":"code","metadata":{"id":"Hm1ExM0R2ceP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608540163992,"user_tz":-360,"elapsed":992,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"2e535ff1-02f9-4b95-c15f-571868f25be4"},"source":["board = Connect4Board()\r\n","negamax = NegamaxSearcher(Connect4Evaluator())\r\n","depth = 1\r\n","\r\n","def print_board(a):\r\n","  a = np.flipud(a)\r\n","  c = {0:'-', 1:'O', -1:'X'}\r\n","  for i in range(a.shape[0]):\r\n","    for j in range(a.shape[1]):\r\n","      print(c[a[i,j]], end=' ')\r\n","    print()\r\n","  print()\r\n","  \r\n","def run(board, first):\r\n","  env = eval_env\r\n","  policy = agent.policy\r\n","\r\n","  print_board(board.to_array())\r\n","\r\n","  turn = 0\r\n","  time_step = env.reset()\r\n","  while not time_step.is_last():\r\n","    if turn != first:\r\n","      action_step = policy.action(time_step)\r\n","      tf_action = action_step.action\r\n","      py_action = tf_action.numpy()[0]\r\n","      print('dqn', end=' ')\r\n","    else:\r\n","      py_action = negamax(board, depth)\r\n","      tf_action = tf.constant([py_action])\r\n","      action_step = policy_step.PolicyStep(tf_action)\r\n","      print('negamax', end=' ')\r\n","    if not board.is_valid_move(py_action):\r\n","      return print('player', 2-turn, 'won')\r\n","    board._make_move(py_action)\r\n","    next_time_step = env.step(tf_action)\r\n","\r\n","    print('move:', py_action)\r\n","    print_board(board.to_array())\r\n","    turn = 1 - turn\r\n","    time_step = next_time_step\r\n","  \r\n","  if board.is_win():\r\n","    if turn == first:\r\n","      print('dqn won')\r\n","    else:\r\n","      print('negamax won')\r\n","  else:\r\n","    print('drawn')\r\n","\r\n","# first: is the agent to move first\r\n","run(board, first=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","\n","dqn move: 3\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - O - - - \n","\n","negamax move: 3\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - X - - - \n","- - - O - - - \n","\n","dqn move: 4\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - X - - - \n","- - - O O - - \n","\n","negamax move: 4\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - X X - - \n","- - - O O - - \n","\n","dqn move: 2\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - X X - - \n","- - O O O - - \n","\n","negamax move: 2\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - X X X - - \n","- - O O O - - \n","\n","dqn move: 5\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - X X X - - \n","- - O O O O - \n","\n","dqn won\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJDNu_AhTpsJ","executionInfo":{"status":"ok","timestamp":1608539481716,"user_tz":-360,"elapsed":971,"user":{"displayName":"Ahnaf Faisal","photoUrl":"","userId":"03543037716766830917"}},"outputId":"090a211f-14de-4f77-e9af-b784179289df"},"source":["board = Connect4Board()\r\n","negamax = NegamaxSearcher(Connect4Evaluator())\r\n","depth = 1\r\n","\r\n","def print_board(a):\r\n","  a = np.flipud(a)\r\n","  c = {0:'-', 1:'O', -1:'X'}\r\n","  for i in range(a.shape[0]):\r\n","    for j in range(a.shape[1]):\r\n","      print(c[a[i,j]], end=' ')\r\n","    print()\r\n","  print()\r\n","  \r\n","def run(board, first):\r\n","  env = eval_env\r\n","  policy = agent.policy\r\n","\r\n","  print_board(board.to_array())\r\n","\r\n","  turn = 0\r\n","  time_step = env.reset()\r\n","  while not time_step.is_last():\r\n","    if turn != first:\r\n","      action_step = policy.action(time_step)\r\n","      tf_action = action_step.action\r\n","      py_action = tf_action.numpy()[0]\r\n","      print('dqn', end=' ')\r\n","    else:\r\n","      py_action = negamax(board, depth)\r\n","      tf_action = tf.constant([py_action])\r\n","      action_step = policy_step.PolicyStep(tf_action)\r\n","      print('negamax', end=' ')\r\n","    if not board.is_valid_move(py_action):\r\n","      return print('player', 2-turn, 'won')\r\n","    board._make_move(py_action)\r\n","    next_time_step = env.step(tf_action)\r\n","\r\n","    print('move:', py_action)\r\n","    print_board(board.to_array())\r\n","    turn = 1 - turn\r\n","    time_step = next_time_step\r\n","  \r\n","  if board.is_win():\r\n","    if turn == first:\r\n","      print('dqn won')\r\n","    else:\r\n","      print('negamax won')\r\n","  else:\r\n","    print('drawn')\r\n","\r\n","# first: is the agent to move first\r\n","run(board, first=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","\n","negamax move: 3\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - O - - - \n","\n","dqn move: 6\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - O - - X \n","\n","negamax move: 2\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - O O - - X \n","\n","dqn move: 1\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- X O O - - X \n","\n","negamax move: 5\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- X O O - O X \n","\n","dqn move: 4\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- X O O X O X \n","\n","negamax move: 4\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - O - - \n","- X O O X O X \n","\n","dqn move: 5\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - O X - \n","- X O O X O X \n","\n","negamax move: 5\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - O - \n","- - - - O X - \n","- X O O X O X \n","\n","dqn move: 2\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - O - \n","- - X - O X - \n","- X O O X O X \n","\n","negamax move: 3\n","- - - - - - - \n","- - - - - - - \n","- - - - - - - \n","- - - - - O - \n","- - X O O X - \n","- X O O X O X \n","\n","dqn move: 5\n","- - - - - - - \n","- - - - - - - \n","- - - - - X - \n","- - - - - O - \n","- - X O O X - \n","- X O O X O X \n","\n","negamax move: 3\n","- - - - - - - \n","- - - - - - - \n","- - - - - X - \n","- - - O - O - \n","- - X O O X - \n","- X O O X O X \n","\n","dqn move: 5\n","- - - - - - - \n","- - - - - X - \n","- - - - - X - \n","- - - O - O - \n","- - X O O X - \n","- X O O X O X \n","\n","negamax move: 3\n","- - - - - - - \n","- - - - - X - \n","- - - O - X - \n","- - - O - O - \n","- - X O O X - \n","- X O O X O X \n","\n","negamax won\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qJtS4Nqxaj0O"},"source":[""],"execution_count":null,"outputs":[]}]}